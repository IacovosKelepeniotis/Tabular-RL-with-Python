{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn, random\n",
    "\n",
    "from gridWorldEnvironment import GridWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating gridworld environment\n",
    "gw = GridWorld(gamma = .9, theta = .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Q-Learning: Off-policy TD Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def state_action_value(env):\n",
    "    q = dict()\n",
    "    for state, action, next_state, reward in env.transitions:\n",
    "        q[(state, action)] = np.random.normal()\n",
    "    for action in env.actions:\n",
    "        q[0, action] = 0\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 'D'): 0,\n",
       " (0, 'L'): 0,\n",
       " (0, 'R'): 0,\n",
       " (0, 'U'): 0,\n",
       " (1, 'D'): 1.0159263422385194,\n",
       " (1, 'L'): -0.9015277224413166,\n",
       " (1, 'R'): -0.8401929147381398,\n",
       " (1, 'U'): -0.3866748964867951,\n",
       " (2, 'D'): -1.6171831004555488,\n",
       " (2, 'L'): -0.757413177831847,\n",
       " (2, 'R'): 1.1948020656778442,\n",
       " (2, 'U'): -0.6814167904466197,\n",
       " (3, 'D'): 0.8048046240684537,\n",
       " (3, 'L'): 0.5058075927359411,\n",
       " (3, 'R'): -0.2396998941031068,\n",
       " (3, 'U'): 0.2155229655857796,\n",
       " (4, 'D'): -1.6147931728590075,\n",
       " (4, 'L'): -0.7788455232241043,\n",
       " (4, 'R'): -1.4834265811813951,\n",
       " (4, 'U'): -0.6831094436413707,\n",
       " (5, 'D'): 0.553787569878218,\n",
       " (5, 'L'): -0.7535460982740707,\n",
       " (5, 'R'): -0.5446399864366045,\n",
       " (5, 'U'): 0.3275946472542217,\n",
       " (6, 'D'): 0.4967878126487371,\n",
       " (6, 'L'): -0.08765553689024165,\n",
       " (6, 'R'): 2.561671991266108,\n",
       " (6, 'U'): -0.6251803976764682,\n",
       " (7, 'D'): -1.4239033515729715,\n",
       " (7, 'L'): 0.8961390571157126,\n",
       " (7, 'R'): -1.752510423129062,\n",
       " (7, 'U'): 0.186255694272231,\n",
       " (8, 'D'): 2.0464864623182057,\n",
       " (8, 'L'): -1.4145441882793333,\n",
       " (8, 'R'): -0.01479790948318322,\n",
       " (8, 'U'): -0.5827888737714622,\n",
       " (9, 'D'): -1.99334821662137,\n",
       " (9, 'L'): -0.2143702145160287,\n",
       " (9, 'R'): 0.3093816164828963,\n",
       " (9, 'U'): -0.13810316479560683,\n",
       " (10, 'D'): -0.4286970274384264,\n",
       " (10, 'L'): -1.0313201895326287,\n",
       " (10, 'R'): 0.674733204171753,\n",
       " (10, 'U'): -0.06485579239030625,\n",
       " (11, 'D'): -1.08761491406436,\n",
       " (11, 'L'): 0.37568985747762257,\n",
       " (11, 'R'): 0.6549082083274831,\n",
       " (11, 'U'): -0.044872797471142374,\n",
       " (12, 'D'): -0.8474472601122482,\n",
       " (12, 'L'): -0.6624032631781939,\n",
       " (12, 'R'): 0.4720691318622512,\n",
       " (12, 'U'): -1.2333806138625314,\n",
       " (13, 'D'): -0.38599325593593187,\n",
       " (13, 'L'): -1.677564721893633,\n",
       " (13, 'R'): -1.1425774085316547,\n",
       " (13, 'U'): -1.3606173055898687,\n",
       " (14, 'D'): -1.1641372208339686,\n",
       " (14, 'L'): 1.1457975665987994,\n",
       " (14, 'R'): -1.012618770180745,\n",
       " (14, 'U'): -0.06091464445082383}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_action_value(gw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_greedy_policy(env, Q):\n",
    "    pi = dict()\n",
    "    for state in env.states:\n",
    "        actions = []\n",
    "        q_values = []\n",
    "        prob = []\n",
    "        \n",
    "        for a in env.actions:\n",
    "            actions.append(a)\n",
    "            q_values.append(Q[state,a])   \n",
    "        for i in range(len(q_values)):\n",
    "            if i == np.argmax(q_values):\n",
    "                prob.append(1)\n",
    "            else:\n",
    "                prob.append(0)       \n",
    "                \n",
    "        pi[state] = (actions, prob)\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def e_greedy(env, e, q, state):\n",
    "    actions = env.actions\n",
    "    action_values = []\n",
    "    prob = []\n",
    "    for action in actions:\n",
    "        action_values.append(q[(state, action)])\n",
    "    for i in range(len(action_values)):\n",
    "        if i == np.argmax(action_values):\n",
    "            prob.append(1 - e + e/len(action_values))\n",
    "        else:\n",
    "            prob.append(e/len(action_values))\n",
    "    return np.random.choice(actions, p = prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def greedy(env, q, state):\n",
    "    actions = env.actions\n",
    "    action_values = []\n",
    "    for action in actions:\n",
    "        action_values.append(q[state, action])\n",
    "    return actions[np.argmax(action_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def q_learning(env, epsilon, alpha, num_iter):\n",
    "    Q = state_action_value(env)\n",
    "    for _ in range(num_iter):\n",
    "        current_state = np.random.choice(env.states)\n",
    "        while current_state != 0:\n",
    "            current_action = e_greedy(env, epsilon, Q, current_state)\n",
    "            next_state, reward = env.state_transition(current_state, current_action)\n",
    "            best_action = greedy(env, Q, next_state)\n",
    "            Q[current_state, current_action] += alpha * (reward + env.gamma * Q[next_state, best_action] - Q[current_state, current_action])\n",
    "            current_state = next_state\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q = q_learning(gw, 0.2, 1.0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 'D'): 0,\n",
       " (0, 'L'): 0,\n",
       " (0, 'R'): 0,\n",
       " (0, 'U'): 0,\n",
       " (1, 'D'): -2.71,\n",
       " (1, 'L'): -1.0,\n",
       " (1, 'R'): -2.71,\n",
       " (1, 'U'): -1.9,\n",
       " (2, 'D'): -3.439,\n",
       " (2, 'L'): -1.9,\n",
       " (2, 'R'): -3.439,\n",
       " (2, 'U'): -2.71,\n",
       " (3, 'D'): -2.71,\n",
       " (3, 'L'): -2.71,\n",
       " (3, 'R'): -3.439,\n",
       " (3, 'U'): -3.439,\n",
       " (4, 'D'): -2.71,\n",
       " (4, 'L'): -1.9,\n",
       " (4, 'R'): -2.71,\n",
       " (4, 'U'): -1.0,\n",
       " (5, 'D'): -3.439,\n",
       " (5, 'L'): -1.9,\n",
       " (5, 'R'): -3.439,\n",
       " (5, 'U'): -1.9,\n",
       " (6, 'D'): -2.71,\n",
       " (6, 'L'): -2.71,\n",
       " (6, 'R'): -2.71,\n",
       " (6, 'U'): -2.71,\n",
       " (7, 'D'): -1.9,\n",
       " (7, 'L'): -3.439,\n",
       " (7, 'R'): -2.71,\n",
       " (7, 'U'): -3.439,\n",
       " (8, 'D'): -3.439,\n",
       " (8, 'L'): -2.71,\n",
       " (8, 'R'): -3.439,\n",
       " (8, 'U'): -1.9,\n",
       " (9, 'D'): -2.71,\n",
       " (9, 'L'): -2.71,\n",
       " (9, 'R'): -2.71,\n",
       " (9, 'U'): -2.71,\n",
       " (10, 'D'): -1.9,\n",
       " (10, 'L'): -3.439,\n",
       " (10, 'R'): -1.9,\n",
       " (10, 'U'): -3.439,\n",
       " (11, 'D'): -1.0,\n",
       " (11, 'L'): -2.71,\n",
       " (11, 'R'): -1.9,\n",
       " (11, 'U'): -2.71,\n",
       " (12, 'D'): -3.439,\n",
       " (12, 'L'): -3.439,\n",
       " (12, 'R'): -2.71,\n",
       " (12, 'U'): -2.71,\n",
       " (13, 'D'): -2.71,\n",
       " (13, 'L'): -3.439,\n",
       " (13, 'R'): -1.9,\n",
       " (13, 'U'): -3.439,\n",
       " (14, 'D'): -1.9,\n",
       " (14, 'L'): -2.71,\n",
       " (14, 'R'): -1.0,\n",
       " (14, 'U'): -2.71}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi_hat = generate_greedy_policy(gw, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_policy(pi, env):\n",
    "    temp = np.zeros(len(env.states) + 2)\n",
    "    for s in env.states:\n",
    "        a = pi_hat[s][0][np.argmax(pi_hat[s][1])]\n",
    "        if a == \"U\":\n",
    "            temp[s] = 0.25\n",
    "        elif a == \"D\":\n",
    "            temp[s] = 0.5\n",
    "        elif a == \"R\":\n",
    "            temp[s] = 0.75\n",
    "        else:\n",
    "            temp[s] = 1.0\n",
    "            \n",
    "    temp = temp.reshape(4,4)\n",
    "    ax = seaborn.heatmap(temp, cmap = \"prism\", linecolor=\"#282828\", cbar = False, linewidths = 0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAFJCAYAAAAxCJwFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1da1f9d8ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### RED = TERMINAL (0)\n",
    "### GREEN = LEFT\n",
    "### BLUE = UP\n",
    "### PURPLE = RIGHT\n",
    "### ORANGE = DOWN\n",
    "\n",
    "show_policy(pi_hat, gw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def double_q_learning(env, epsilon, alpha, num_iter):\n",
    "    Q1, Q2  = state_action_value(env), state_action_value(env)\n",
    "    for _ in range(num_iter):\n",
    "        current_state = np.random.choice(env.states)\n",
    "        while current_state != 0:\n",
    "            Q = dict()\n",
    "            for key in Q1.keys():\n",
    "                Q[key] = Q1[key] + Q2[key]\n",
    "            current_action = e_greedy(env, epsilon, Q, current_state)\n",
    "            next_state, reward = env.state_transition(current_state, current_action)\n",
    "            chosen_Q = np.random.choice([\"Q1\", \"Q2\"])\n",
    "            if chosen_Q == \"Q1\":\n",
    "                best_action = greedy(env, Q1, next_state)\n",
    "                Q1[current_state, current_action] += alpha * \\\n",
    "                    (reward + env.gamma * Q2[next_state, best_action] - Q1[current_state, current_action])\n",
    "            else:\n",
    "                best_action = greedy(env, Q2, next_state)\n",
    "                Q2[current_state, current_action] += alpha * \\\n",
    "                    (reward + env.gamma * Q1[next_state, best_action] - Q2[current_state, current_action])\n",
    "            current_state = next_state\n",
    "    return Q1, Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q1, Q2 = double_q_learning(gw, 0.2, 0.5, 5000)\n",
    "\n",
    "Q = dict()\n",
    "for key in Q1.keys():\n",
    "    Q[key] = Q1[key] + Q2[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_hat = generate_greedy_policy(gw, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAFJCAYAAAAxCJwFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1da1fa52390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### RED = TERMINAL (0)\n",
    "### GREEN = LEFT\n",
    "### BLUE = UP\n",
    "### PURPLE = RIGHT\n",
    "### ORANGE = DOWN\n",
    "\n",
    "show_policy(pi_hat, gw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
